{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import requests\n",
    "from xlsxwriter.utility import xl_rowcol_to_cell\n",
    "sys.path.append(r'/home/jupyter/reusable_code')\n",
    "import google_api_functions as gaf\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Set up modules for Google functionality\n",
    "from google.cloud import bigquery # To run BQ statements\n",
    "from google_auth_oauthlib import flow # To authorise as user\n",
    "from googleapiclient.discovery import build # To pull in from sheets, slides etc. API\n",
    "from google.auth.transport.requests import Request\n",
    "from google.cloud.bigquery import magics\n",
    "import google\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(actual, estimated): \n",
    "    actual, estimated = np.array(actual), np.array(estimated)\n",
    "    return np.mean(np.abs((actual - estimated) / actual)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds=gaf.Authenticate_Google(r\"/home/jupyter/reusable_code/\") #GAF is a package steve created with a list of useful functions\n",
    "bq = bigquery.Client(project='itv-bde-analytics-dev',credentials=creds) #Apply credentials to BQ client \"bq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the FTS table created in BQ\n",
    "\n",
    "query=\"\"\"\n",
    "select *\n",
    "from `itv-bde-analytics-dev.britbox_sandbox.SB_4hourly_FTS`\n",
    ";\n",
    "\"\"\"\n",
    "FTS_df = bq.query(query).to_dataframe()\n",
    "FTS_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column names (was relevant when using steves code)\n",
    "FTS_df = FTS_df.rename(columns={ 'starting_hour':'reporting date','FTS':'N'})\n",
    "\n",
    "# Indexes the date column \n",
    "FTS_df = FTS_df.set_index(\"reporting date\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the data\n",
    "FTS_df = FTS_df.sort_index()\n",
    "FTS_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative way of generating loop\n",
    "import itertools\n",
    "p_values = range(0,3)\n",
    "d_values = range(0,2)\n",
    "q_values = range(0,2)\n",
    "s_values=[6,0] #Weekly, daily, none\n",
    "pdq = list(itertools.product(p_values, d_values, q_values))\n",
    "PDQ = list(itertools.product(p_values, d_values, q_values,s_values))\n",
    "arima_combos=list(itertools.product(pdq,PDQ))\n",
    "arima_combos=[i for i in arima_combos if i[0]!=(0,0,0)] # Remove all the 0,0,0 combos\n",
    "print(len(pdq))\n",
    "print(len(arima_combos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr='Hello {0} and {0}!'.format('Sammy','Steve')\n",
    "cmystr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist=['A','B','C']\n",
    "\n",
    "for n,val in enumerate(mylist):\n",
    "    print(n,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARIMA_params={i:(['ar.L{}'.format(x+1) for x in range(0,i[0])],['ma.L{}'.format(x+1) for x in range(0,i[2])]) for i in pdq}\n",
    "ARIMA_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params=[]\n",
    "for i in arima_combos:\n",
    "    [all_params.append(item) for sublist in [x for x in ARIMA_params[i[0]]]+[y for y in SARIMA_params[i[1]]]+[['sigma2']] for item in sublist]\n",
    "start_params=pd.Series({x:0.01 for x in set(all_params)})\n",
    "start_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_paramids = pd.Series([item for sublist in [x for x in ARIMA_params[(1,0,0)]]+[y for y in SARIMA_params[(1,0,0,6)]]+[['sigma2']] for item in sublist])\n",
    "start_params.filter(items=keep_paramids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train,test = FTS_df['2019-11-11 00:00:00':'2020-10-31 20:00:00'], FTS_df['2020-11-01 00:00:00':'2020-11-16 20:00:00']\n",
    "errors=[]\n",
    "errors2=[]\n",
    "predictions = list()\n",
    "\n",
    "# Initialise best model dictionary\n",
    "best_model={'MAPE':999999999.0}\n",
    "\n",
    "# Generate dictionary of the parameters that will be needed for each iteration of the model\n",
    "ARIMA_params={i:(['ar.L{}'.format(x+1) for x in range(0,i[0])],['ma.L{}'.format(x+1) for x in range(0,i[2])]) for i in pdq}\n",
    "SARIMA_params={i:(['ar.S.L{}'.format((x+1)*i[3]) for x in range(0,i[0])],['ma.S.L{}'.format((x+1)*i[3]) for x in range(0,i[2])]) for i in PDQ}\n",
    "\n",
    "all_params=[]\n",
    "for i in arima_combos:\n",
    "    [all_params.append(item) for sublist in [x for x in ARIMA_params[i[0]]]+[y for y in SARIMA_params[i[1]]]+[['sigma2']] for item in sublist]\n",
    "start_params=pd.Series({x:0.01 for x in set(all_params)})\n",
    "\n",
    "\n",
    "for n,i in enumerate(reversed(arima_combos)):\n",
    "    try:\n",
    "        keep_paramids = pd.Series([item for sublist in [x for x in ARIMA_params[i[0]]]+[y for y in SARIMA_params[i[1]]]+[['sigma2']] for item in sublist])\n",
    "        if i[0]!=(0,0,0):\n",
    "            if i[1][3]==0: \n",
    "                model=ARIMA(train,order=i[0],freq='4H') # Initialise ARIMA class\n",
    "\n",
    "                print('Starting ARIMA for {}  at {}'.format(i,datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "                model_fit = model.fit(disp=0)  # Actually fit the ARIMA\n",
    "\n",
    "                print('Finished ARIMA for {}  at {}'.format(i,datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "                pred_y = model_fit.forecast(steps=len(test))[0]# create a forecast for the \"expected\" values on the Test Dataset\n",
    "\n",
    "            else:\n",
    "         #   try:\n",
    "\n",
    "                model=SARIMAX(train, order=i[0], seasonal_order=i[1],freq='4h', simple_differencing=True) # Initialise SARIMAX class\n",
    "\n",
    "                print('Starting SARIMAX for {} at {}'.format(i,datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "                #print(start_params.filter(items=keep_paramids))\n",
    "                # Actually fit the SARIMAX\n",
    "                init_params=start_params.filter(items=keep_paramids)\n",
    "                print(init_params)\n",
    "                model_fit = model.fit(disp=0,low_memory=True,start_params=init_params) #start params are filtered and sorted according to keep_paramids\n",
    "                #model_fit = model.fit(disp=0,low_memory=True) # Actually fit the SARIMAX\n",
    "                print('Finished SARIMAX for {}  at {}'.format(i,datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "                print(model_fit.params)\n",
    "\n",
    "                pred_y = model_fit.forecast(steps=len(test)) # create a forecast for the \"expected\" values on the Test Dataset\n",
    "\n",
    "            predictions.append(pred_y)\n",
    "\n",
    "            error = mean_squared_error(test,pred_y)\n",
    "            error2 = mean_absolute_percentage_error(test,pred_y)\n",
    "\n",
    "            if error2*100<best_model['MAPE']:\n",
    "\n",
    "                print('{} was this model''s error, and {} is the previous best so model will update'.format(error2*100,best_model['MAPE']))\n",
    "                # Update view of what best model is\n",
    "                best_model={'model':model_fit\\\n",
    "                           ,'modelParams':model_fit.params\\\n",
    "                           ,'modelParamsConfInt':model_fit.conf_int()\\\n",
    "                            ,'ARIMA':i[0]\\\n",
    "                            ,'SARIMA':i[1]\\\n",
    "                            ,'RMSE':np.sqrt(error)\n",
    "                            ,'MAPE':error2*100\n",
    "                           }\n",
    "                # Update Start Params to hopefully optimise future loops\n",
    "                start_params=model_fit.params.combine_first(start_params)\n",
    "            errors.append(error)\n",
    "            errors2.append(error2)\n",
    "            print(i[0],i[1], np.sqrt(error), error2*100)\n",
    "    except:\n",
    "        print('Could not fit model {}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i[0],i[1])\n",
    "model=SARIMAX(train, order=(0,1,1), seasonal_order=(1,1,1,42), simple_differencing=True,freq='4H')\n",
    "            \n",
    "timenow=datetime.now()\n",
    "print('Starting SARIMAX for {} at {}'.format(i,timenow.strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "model_fit = model.fit(disp=0,low_memory=True,freq='4H')\n",
    "timenow=datetime.now()\n",
    "print('Finished SARIMAX for {}  at {}'.format(i,timenow.strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "            \n",
    "\n",
    "#help(model_fit)\n",
    "print(model_fit.model) # Model instance\n",
    "print(model_fit.params)# Actual params\n",
    "model_fit.conf_int() # Confidence intervals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model_fit.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_params=model_fit.params\n",
    "\n",
    "model=SARIMAX(train, order=(1,1,1), seasonal_order=(1,1,1,42), simple_differencing=True,freq='4H')\n",
    "            \n",
    "timenow=datetime.now()\n",
    "print('Starting SARIMAX for {} at {}'.format(i,timenow.strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "model_fit = model.fit(disp=0,low_memory=True,freq='4H',start_params=last_params)\n",
    "timenow=datetime.now()\n",
    "print('Finished SARIMAX for {}  at {}'.format(i,timenow.strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "            \n",
    "\n",
    "#help(model_fit)\n",
    "print(model_fit.model) # Model instance\n",
    "print(model_fit.params)# Actual params\n",
    "model_fit.conf_int() # Confidence intervals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "last_params=model_fit.params\n",
    "print(i[0],i[1])\n",
    "model=SARIMAX(train, order=(0,1,1), seasonal_order=(1,1,1,42), simple_differencing=True,freq='4H')\n",
    "            \n",
    "timenow=datetime.now()\n",
    "print('Starting SARIMAX for {} at {}'.format(i,timenow.strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "model_fit = model.fit(disp=0,low_memory=True,freq='4H',start_params=last_params)\n",
    "timenow=datetime.now()\n",
    "print('Finished SARIMAX for {}  at {}'.format(i,timenow.strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "            \n",
    "\n",
    "#help(model_fit)\n",
    "print(model_fit.model) # Model instance\n",
    "print(model_fit.params)# Actual params\n",
    "model_fit.conf_int() # Confidence intervals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_params_dict={'ar.L1':0.00,\\\n",
    "                   'ma.L1':0.00,\\\n",
    "'ar.S.L42':0.00,\\\n",
    "'ma.S.L42':0.00,\\\n",
    "'sigma2':0.00}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_params=pd.Series(start_params_dict)\n",
    "start_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params_dict={'ar.L1':1.20,\\\n",
    "                   'ma.L1':0.99}\n",
    "new_params=pd.Series(new_params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_params=new_params.combine_first(start_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_params=pd.Series({'ar.L1':0.00,\\\n",
    "                   'ma.L1':0.00,\\\n",
    "'ar.S.L42':0.00,\\\n",
    "'ma.S.L42':0.00,\\\n",
    "'sigma2':0.00})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=((0,1,1),(1,1,0,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x[y for y in x] for x in i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramids=pd.Series(['ar.L1','i1','ma.L1','ar.S.L42','i2','ma.S.L42','sigma2'])\n",
    "hyperparameters=pd.Series([item for sublist in i for item in sublist])\n",
    "keep_paramids=paramids[hyperparameters>0]\n",
    "start_params.filter(items=keep_paramids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_paramids.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = range(0,3)\n",
    "d_values = range(0,2)\n",
    "q_values = range(0,3)\n",
    "s_values=[42,6,0] #Weekly, daily, none\n",
    "pdq = list(itertools.product(p_values, d_values, q_values))\n",
    "PDQ = list(itertools.product(p_values, d_values, q_values,s_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARIMA_params={i:(['ar.L{}'.format(x+1) for x in range(0,i[0])],['ma.L{}'.format(x+1) for x in range(0,i[2])]) for i in pdq}\n",
    "SARIMA_params={i:(['ar.S.L{}'.format((x+1)*i[3]) for x in range(0,i[0])],['ma.S.L{}'.format((y+1)*i[3]) for y in range(0,i[2])]) for i in PDQ}\n",
    "\n",
    "ARIMA_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "SARIMA_params={i:(['ar.S.L{}'.format((x+1)*i[3]) for x in range(0,i[0])],['ma.S.L{}'.format((y+1)*i[3]) for y in range(0,i[2])]) for i in PDQ}\n",
    "SARIMA_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train,test = FTS_df['2019-11-11 00:00:00':'2020-10-31 20:00:00'], FTS_df['2020-11-01 00:00:00':'2020-11-16 20:00:00']           \n",
    "errors=[]\n",
    "errors2=[]\n",
    "predictions = list()\n",
    "\n",
    "# Initialise best model dictionary\n",
    "best_model={'MAPE':999999999.0}\n",
    "\n",
    "# Generate dictionary of the parameters that will be needed for each iteration of the model\n",
    "ARIMA_params={i:(['ar.L{}'.format(x+1) for x in range(0,i[0])],['ma.L{}'.format(x+1) for x in range(0,i[2])]) for i in pdq}\n",
    "SARIMA_params={i:(['ar.S.L{}'.format((x+1)*i[3]) for x in range(0,i[0])],['ma.S.L{}'.format((x+1)*i[3]) for x in range(0,i[2])]) for i in PDQ}\n",
    "\n",
    "all_params=[]\n",
    "for i in arima_combos:\n",
    "    [all_params.append(item) for sublist in [x for x in ARIMA_params[i[0]]]+[y for y in SARIMA_params[i[1]]]+[['sigma2']] for item in sublist]\n",
    "start_params=pd.Series({x:0.00 for x in set(all_params)})\n",
    "\n",
    "for i in reversed(arima_combos):\n",
    "    keep_paramids = pd.Series([item for sublist in [x for x in ARIMA_params[i[0]]]+[y for y in SARIMA_params[i[1]]]+[['sigma2']] for item in sublist])\n",
    "    print(keep_paramids)\n",
    "    print(start_params.filter(items=keep_paramids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = FTS_df['2019-11-11 00:00:00':'2020-10-31 20:00:00'], FTS_df['2020-11-01 00:00:00':'2020-11-16 20:00:00']           \n",
    "errors=[]\n",
    "errors2=[]\n",
    "predictions = list()\n",
    "\n",
    "# Initialise best model dictionary\n",
    "best_model={'MAPE':999999999.0}\n",
    "\n",
    "# Generate dictionary of the parameters that will be needed for each iteration of the model\n",
    "ARIMA_params={i:(['ar.L{}'.format(x+1) for x in range(0,i[0])],['ma.L{}'.format(x+1) for x in range(0,i[2])]) for i in pdq}\n",
    "SARIMA_params={i:(['ar.S.L{}'.format((x+1)*i[3]) for x in range(0,i[0])],['ma.S.L{}'.format((x+1)*i[3]) for x in range(0,i[2])]) for i in PDQ}\n",
    "\n",
    "all_params=[]\n",
    "for i in arima_combos:\n",
    "    [all_params.append(item) for sublist in [x for x in ARIMA_params[i[0]]]+[y for y in SARIMA_params[i[1]]]+[['sigma2']] for item in sublist]\n",
    "start_params=pd.Series({x:0.00 for x in set(all_params)})\n",
    "start_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1=pd.Series(['A','B','C'])\n",
    "ser2=pd.Series([2,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1.filter(items=ser2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "           \n",
    "           \n",
    "model=SARIMAX(train, order=(0, 0, 1), seasonal_order=(1, 0, 1, 42),freq='4h', simple_differencing=True) # Initialise SARIMAX class\n",
    "print('Starting SARIMAX for {} at {}'.format(i,datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "model_fit = model.fit(disp=0,low_memory=True) #start params are filtered and sorted according to keep_paramids\n",
    "print('Finished SARIMAX for {}  at {}'.format(i,datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "print(model_fit.params)\n",
    "\n",
    "pred_y = model_fit.forecast(steps=len(test)) # create a forecast for the \"expected\" values on the Test Dataset\n",
    "\n",
    "predictions.append(pred_y)\n",
    "\n",
    "error = mean_squared_error(test,pred_y)\n",
    "error2 = mean_absolute_percentage_error(test,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Upper_Bound=train.mean()+(3*train.std())\n",
    "Upper_Bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['N']>Upper_Bound[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Upper_Bound[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Upper_Bound=train.mean()+(3*train.std())\n",
    "train['N2'] = np.where(train['N']>Upper_Bound[0], Upper_Bound[0],train['N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "r-cpu.3-6.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.3-6:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
