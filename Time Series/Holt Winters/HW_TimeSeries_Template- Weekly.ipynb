{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import requests\n",
    "sys.path.append(r'/home/jupyter/reusable_code')\n",
    "import google_api_functions as gaf\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from matplotlib import pyplot\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Set up modules for Google functionality\n",
    "from google.cloud import bigquery # To run BQ statements\n",
    "from google_auth_oauthlib import flow # To authorise as user\n",
    "from googleapiclient.discovery import build # To pull in from sheets, slides etc. API\n",
    "from google.auth.transport.requests import Request\n",
    "from google.cloud.bigquery import magics\n",
    "import google\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Interpolate_Missing (df,freq='d'):\n",
    "    df=df.reindex(pd.date_range(start=df.index.min(), end=df.index.max(),freq=freq))\n",
    "    df=df.interpolate()\n",
    "    return df\n",
    "\n",
    "def Cap_data (ser,show_info=True):\n",
    "    \n",
    "    newSer=ser.copy() # Make a deep copy of the series to manipulate, without affecting original series\n",
    "    \n",
    "    if type(ser) is pd.core.series.Series : # Check if series\n",
    "        skewvalue=ser.skew()\n",
    "        print('The skew is {:.2f}. A value of <-1 indicates lots of small values, and a value of >1 indicates the presence of some large values.'.format(skewvalue))\n",
    "        \n",
    "        if show_info==True:\n",
    "            print(ser.describe())\n",
    "            ser.hist()\n",
    "            plt.show()\n",
    "        if skewvalue>1:\n",
    "            threshold=newSer.quantile(0.99)# For lots of large values, consider the 99th percentile as the threshold\n",
    "            mask=newSer>threshold # Create the boolean mask for all the records exceeding the threshold\n",
    "            \n",
    "            affected_records=mask[mask==True].size # Identify how many records affected\n",
    "            series_size=newSer.size # How many records in dataset\n",
    "            pc_affected=float(affected_records)/float(series_size)*100\n",
    "            \n",
    "            newSer=newSer.mask(newSer>threshold,threshold)  # Apply the mask\n",
    "            print('The 99th percentile is {}. Values greater than this will be capped, amounting to {:.0f} records and {:.1f}% of the dataset.'.format(threshold,affected_records,pc_affected))\n",
    "        elif skewvalue<-1:\n",
    "            threshold=newSer.quantile(0.01)[columnname] # For lots of large values, consider the 99th percentile as the threshold\n",
    "            mask=newSer<threshold # Create the boolean mask for all the records exceeding the threshold\n",
    "            \n",
    "            affected_records=mask[mask==True].size # Identify how many records affected\n",
    "            series_size=newSer.size # How many records in dataset\n",
    "            pc_affected=float(affected_records)/float(series_size)*100\n",
    "            #newSer= np.where(newSer<threshold, threshold,newSer)  # Apply the mask\n",
    "            newSer=newSer.mask(newSer<threshold,threshold)\n",
    "            print('The 1st percentile is {}. Values less than this will be capped, amounting to {:.0f} records and {:.1f}% of the dataset.'.format(threshold,affected_records,pc_affected))\n",
    "            \n",
    "        else:\n",
    "            print('Skew is ok, no capping applied')\n",
    "            \n",
    "        newskew=newSer.skew()\n",
    "        print('The skew is now {:.2f}.'.format(newskew))\n",
    "        \n",
    "        if show_info==True:\n",
    "            print(newSer.describe())\n",
    "            newSer.hist()  \n",
    "            plt.show()\n",
    "        \n",
    "        \n",
    "    \n",
    "    elif type(ser) is pd.core.frame.DataFrame and ser.shape[1]==1: # Check if one-column dataframe, if so take the first column and reference throughout for the processing\n",
    "        columnname=ser.columns[0] #Get the name of the series to use later\n",
    "        skewvalue=ser[columnname].skew()\n",
    "        print('The skew is {:.2f}. A value of <-1 indicates lots of small values, and a value of >1 indicates the presence of some large values.'.format(skewvalue))\n",
    "        \n",
    "        if show_info==True:\n",
    "            print(ser.describe())\n",
    "            ser.hist()\n",
    "            plt.show()\n",
    "        if skewvalue>1:\n",
    "            threshold=newSer.quantile(0.99)[columnname] # For lots of large values, consider the 99th percentile as the threshold\n",
    "            mask=newSer[columnname]>threshold # Create the boolean mask for all the records exceeding the threshold\n",
    "            print(mask[columnname==True])\n",
    "            affected_records=mask[mask==True].size # Identify how many records affected\n",
    "            series_size=newSer.size # How many records in dataset\n",
    "            pc_affected=float(affected_records)/float(series_size)*100\n",
    "            newSer[columnname]= np.where(mask, threshold,newSer[columnname])  # Apply the mask\n",
    "            print('The 99th percentile is {}. Values greater than this will be capped, amounting to {:.0f}/{:.0f} records ({:.1f}% of the dataset).'.format(threshold,affected_records,series_size,pc_affected))\n",
    "        \n",
    "        elif skewvalue<-1:\n",
    "            threshold=newSer.quantile(0.01)[columnname] # For lots of large values, consider the 99th percentile as the threshold\n",
    "            mask=newSer[columnname]<threshold # Create the boolean mask for all the records exceeding the threshold\n",
    "            print(mask[columnname==True])\n",
    "            affected_records=mask[mask==True].size # Identify how many records affected\n",
    "            series_size=newSer.size # How many records in dataset\n",
    "            pc_affected=float(affected_records)/float(series_size)*100\n",
    "            newSer[columnname]= np.where(mask, threshold,newSer[columnname])  # Apply the mask\n",
    "            print('The 1st percentile is {}. Values less than this will be capped, amounting to {:.0f}/{:.0f} records ({:.1f}% of the dataset).'.format(threshold,affected_records,series_size,pc_affected))\n",
    "        \n",
    "        else:\n",
    "            print('Skew is ok, no capping applied')\n",
    "            \n",
    "        newskew=newSer[columnname].skew()\n",
    "        print('The skew is now {:.2f}.'.format(newskew))\n",
    "        \n",
    "        if show_info==True:\n",
    "            print(newSer[columnname].describe())\n",
    "            newSer.hist()  \n",
    "            plt.show()\n",
    "\n",
    "    else:\n",
    "        print('Can''t run data, needs to be a 1 column dataframe or a series')\n",
    "    return newSer\n",
    "\n",
    "def generate_test_trains(df,HoldoutPC=0.05,recenttrain=90,lowerCutoff=None,upperCutoff=None):\n",
    "    \n",
    "    if lowerCutoff:\n",
    "        df=df[lowerCutoff:]\n",
    "    if upperCutoff:\n",
    "        df=df[:upperCutoff]\n",
    "    \n",
    "    # This function splits the samples into three groups. A holdout is taken from the most recent data, used to evaluate model fit. The proportion to hold out is determined by HoldoutPC    \n",
    "    # Two different training sets are generated. One uses all available data, the other uses the most recent N periods, on the proviso that older day may no longer be relevant so models \n",
    "    # trained on this data may be better\n",
    "    \n",
    "    # If for whatever reason we wish to trim the edges (i.e. we want to build a model for \"last week\", this can be done using the lower- and upperCutoff)\n",
    "    \n",
    "    holdoutsize=int(np.floor(len(df)*HoldoutPC))\n",
    "    holdout=df[-holdoutsize:]\n",
    "    print('{} records used as a test dataset ranging from {} and {}.'.format(holdoutsize,holdout.index.min() ,holdout.index.max()))\n",
    "    fullTrain=df[:-holdoutsize]\n",
    "    print('{} records used in the \"Full Training\" dataset ranging from {} and {}.'.format(len(fullTrain),fullTrain.index.min() ,fullTrain.index.max()))\n",
    "    recentTrain=fullTrain[-recenttrain:]\n",
    "    print('{} records used in the \"Recent Data\" training dataset ranging from {} and {}.'.format(len(recentTrain),recentTrain.index.min() ,recentTrain.index.max()))\n",
    "    return(holdout,fullTrain,recentTrain)\n",
    "\n",
    "def timeSeries_diagnostics(ser,hypothesised_seasonality=7):\n",
    "    if type(ser) is pd.core.series.Series :  \n",
    "        print(\"Correlation at lag 1 is :\",ser.autocorr())\n",
    "\n",
    "        # Correlation with itself (7 days ago)\n",
    "        print(\"Correlation at lag {} is :\".format(hypothesised_seasonality),ser.autocorr(hypothesised_seasonality))\n",
    "\n",
    "        xcutoff=hypothesised_seasonality*3+1 # Show three seasonal periods to see if that is validated\n",
    "        plot_acf(ser, lags=xcutoff)\n",
    "\n",
    "        \n",
    "        # Get Partial ACF\n",
    "\n",
    "        PACF_values=pd.DataFrame(pacf(ser,nlags=xcutoff)) #PACF numpy array converted to df\n",
    "        #PACF_values.plot() #Plot\n",
    "        #pyplot.show()\n",
    "        plot_pacf(ser)\n",
    "        print(\"Reminder- the point at which PACF drops to 0 is the point at which no further value is added by this lag over and above the points before it\")\n",
    "\n",
    "    else:\n",
    "        print('Please pass a Pandas Series for evaluation')\n",
    "\n",
    "def HW_grid(seasonal=[7]):\n",
    "    Initial_grid=list(itertools.product(['add','mul'],['add','mul',None],seasonal))\n",
    "    Deduped_grid=list(set([(i[0],i[1],i[2]) if i[1]!=None else (i[0],i[1],0) for i in Initial_grid ])) # If seasonality is none, we don't need the individual variantsv `    \n",
    "     #Create all 6 combos of additive, multiplicative multiplied by the seasonal\n",
    "    return Deduped_grid\n",
    "\n",
    "\n",
    "def Remove_duplicate_training_sets(training_sets):\n",
    "    if type(training_sets)!=dict:\n",
    "        print ('ERROR: training_sets parameter needs to take the form of a dictionary {label: pandas series}')\n",
    "    else:\n",
    "        del_dict={x:False for x in training_sets} #Create a dictionary saying which sets to delete, default to None\n",
    "        for n1,x in enumerate(training_sets): # Loop training sets\n",
    "            for n2,y in enumerate(training_sets): # For each set\n",
    "                if x==y or n2<n1: # Don't check references to self and only look at outstanding combinations\n",
    "                    pass\n",
    "                else:\n",
    "                    print('Comparing {} with {}'.format(x,y))\n",
    "                    if training_sets[x].equals(training_sets[y]): # If any other series are duplicate\n",
    "                        del_dict[y]=True # Mark them for deletion\n",
    "        # Now actually delete if appropriate\n",
    "        for i in del_dict:\n",
    "            if del_dict[i]==True:\n",
    "                del training_sets[i]\n",
    "    return training_sets\n",
    "\n",
    "def error_calcs(actual, estimated): \n",
    "    actual, estimated = np.array(actual), np.array(estimated)\n",
    "    nobs=len(actual)\n",
    "    \n",
    "    fit_dict={'MAPE':np.mean(np.abs(actual - estimated) / actual) ,\n",
    "             'MSE':np.mean((actual - estimated)**2),\n",
    "             'RMSE':np.sqrt(np.mean((actual - estimated)**2)),\n",
    "             'MAE':np.mean(np.abs(actual - estimated)),\n",
    "             'Correlation': np.corrcoef(actual , estimated)[0][1]}\n",
    "    \n",
    "    return fit_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Get Time Series data. This should be a Pandas series, with the datetime as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free Trial Starts Time Series\n",
    "creds=gaf.Authenticate_Google(r\"/home/jupyter/reusable_code/\") #GAF is a package steve created with a list of useful functions\n",
    "bq = bigquery.Client(project='itv-bde-analytics-dev',credentials=creds) #Apply credentials to BQ client \"bq\"\n",
    "\n",
    "# Read in the FTS table created in BQ\n",
    "query=\"\"\"\n",
    "select \n",
    "  timestamp_trunc(start,WEEK) as reportingDate\n",
    "  , count(*) as vol \n",
    "from `itv-bde-analytics-dev.britbox_sandbox.ss_entitlements` \n",
    "where eventSubType.reportingEvent = 'A' and billingProvider in ('Stripe', 'iTunes') \n",
    "and timestamp_trunc(start,WEEK)<timestamp_trunc(current_timestamp(),WEEK)\n",
    "group by \n",
    "  1\n",
    "\"\"\"\n",
    "FTS_df = bq.query(query).to_dataframe()\n",
    "\n",
    "# Change the column names\n",
    "FTS_df = FTS_df.rename(columns={ 'reportingDate':'reporting date','vol':'N'})\n",
    "\n",
    "# Indexes the date column \n",
    "TS = FTS_df.set_index(\"reporting date\")\n",
    "TS=TS.tz_localize(None) # Remove timezone from FTS_df index\n",
    "\n",
    "TS=pd.Series(TS['N'])\n",
    "TS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Clean up the data & generate training/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate any missing days\n",
    "TS=Interpolate_Missing(TS,freq='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap outliers\n",
    "TS_capped=Cap_data(TS,show_info=False)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_test, TS_fullTrain, TS_recentTrain=generate_test_trains(TS,HoldoutPC=0.10,upperCutoff='2020-11-15')\n",
    "TS_capped_test, TS_capped_fullTrain, TS_capped_recentTrain=generate_test_trains(TS_capped,HoldoutPC=0.10,upperCutoff='2020-11-15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Visual inspection of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSeries_diagnostics(TS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Grid Search across iterations of Holt Winters\n",
    "Combinations include: \n",
    "* Additive & Multiplicative for the trend element\n",
    "* Seasonal element Y/N, and if Yes, Additive and Multiplicative\n",
    "* Different seasonal lags to try (if desired, change the  \"seasonal\" list. Default is 7 only\n",
    "\n",
    "Additionally there are up to 4 datasets to train on\n",
    "* The Full data\n",
    "* The Recent data (i.e. the subset of full data to take more recent obs only)\n",
    "* The Full data, with outliers removed\n",
    "* The Recent data, with outliers removed\n",
    "\n",
    "Obviously some of these datasets may be duplicates of each other, e.g. if the \"recent\" threshold covers all time, or if no outliers were detected. If so, these should be removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=HW_grid(seasonal=[2]) # Create a Holt-Winters hyperparameter search grid\n",
    "training_sets={'Full training':TS_fullTrain, 'Recent training':TS_recentTrain,'Full training (capped)':TS_capped_fullTrain, 'Recent training (capped)':TS_capped_recentTrain}\n",
    "training_sets=Remove_duplicate_training_sets(training_sets) # Run a function to exclude any training datasets that may be copies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to fit the models:\n",
    "##### 0) Loop through training sets and model hyperparameter grid to enable next step\n",
    "#####  1) Define the model's hyperparameters & training set\n",
    "##### 2) Fit the model to return the optimised parameters\n",
    "##### 3) Use the fitted model to forecast N steps ahead, where N is the size of the test/validation set\n",
    "##### 4) Evaluate the N step model fit (MAPE, RMSE, etc.)\n",
    "\n",
    "##### 5) Use the fitted model to then forecast N x 1-step forecasts (i.e. with up to date data, how well does it predict tomorrow).\n",
    " Importantly for this step, the paramaters are now fixed, but the trends etc. can be updated with real data. This is in contrast to step 3 & 4 where data cuts off at the end of the training \n",
    " set, and thereafter the data is simply using past predictions to model future predictions, eventually resulting in a uniform pattern\n",
    "##### 6) Evaluate the N x 1-step model fit (MAPE, RMSE, etc.)\n",
    "##### 7) Store all the results etc. in a dictionary, and append to a list of all iterations\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafreq='w' # Define data frequency\n",
    "hw_models=[] # Initialise \n",
    "\n",
    "#### 0) Loop through training sets and model hyperparameter grid to enable next step\n",
    "for ser in training_sets: # For each training set\n",
    "    for hyperparams in grid: # For each hyperparameter combo\n",
    "        print(\"Fitting {} on dataset {}\".format(hyperparams,ser))\n",
    "        model =None\n",
    "        model_fit=None\n",
    "        #####  1) Define the model's hyperparameters & training set. NB this doesn't \"run\" the model.\n",
    "        if hyperparams[1]==None:\n",
    "            model=ExponentialSmoothing(training_sets[ser], trend=hyperparams[0],freq=datafreq)\n",
    "        else:\n",
    "            model=ExponentialSmoothing(training_sets[ser], trend=hyperparams[0],seasonal=hyperparams[1]\\\n",
    "                                       ,seasonal_periods=hyperparams[2],freq=datafreq)\n",
    "            \n",
    "        ##### 2) Fit the model to return the optimised parameters\n",
    "        print('Optimising...')\n",
    "        model_fit=model.fit() \n",
    "        #print(model_fit.mle_retvals)\n",
    "        ##### 3) Use the fitted model to forecast N steps ahead, where N is the size of the test/validation set\n",
    "        nStepPred=model_fit.model.predict(params=model_fit.params,start=TS_test.index.min(),end=TS_test.index.max())\n",
    "\n",
    "        ##### 4) Evaluate the N step model fit (MAPE, RMSE, etc.)\n",
    "        nStepfit=error_calcs(TS_test,nStepPred) \n",
    "        nStepfit['AIC']=model_fit.aic # Add AIC\n",
    "\n",
    "       ##### 5) Use the fitted model to then forecast N x 1-step forecasts (i.e. with up to date data, how well does it predict tomorrow).\n",
    "        newTrain=training_sets[ser].append(TS_test) # Append the test data onto the existing training set\n",
    "        \n",
    "        # In StatsModels prior to v 0.12 you set all the params in the model.fit, but couldn't pass seasonal starting parameters\n",
    "        # Since v 0.12 you set the initialisation upfront in the model= statement, and the use_boxcox parameter, but the rest are set in the model.fit, just to confuse you\n",
    "        \n",
    "        paramdictModel= {key: value for key, value in model_fit.params.items() if (re.split('_',key)[0]=='initial' or key in ['use_boxcox'])}\n",
    "        paramdictFit= {key: value for key, value in model_fit.params.items() if key not in [key for key in paramdictModel]+['lamda']}\n",
    "        try:\n",
    "            paramdictModel['initial_seasonal'] = paramdictModel.pop('initial_seasons')\n",
    "        except:\n",
    "            pass\n",
    "        # Redefine the model to point at the new, longer training set (\"newTrain\")\n",
    "        if hyperparams[1]==None:\n",
    "            paramdictModel={key: value for key, value in paramdictModel.items() if len(re.findall('season',key))==0} # Remove seasonal parameters for non-seasonal models (they're empty anyway but still passed in the results Wrapper)\n",
    "            paramdictFit={key: value for key, value in paramdictFit.items() if len(re.findall('season',key))==0} # Remove seasonal parameters for non-seasonal models\n",
    "            \n",
    "            retrained_model=ExponentialSmoothing(newTrain, trend=hyperparams[0],freq=datafreq,initialization_method='known', **paramdictModel)\n",
    "        else:\n",
    "            \n",
    "            \n",
    "            retrained_model=ExponentialSmoothing(newTrain, trend=hyperparams[0],seasonal=hyperparams[1]\\\n",
    "                                       ,seasonal_periods=hyperparams[2],freq=datafreq,initialization_method='known', **paramdictModel)\n",
    "        print('Refitting without optimisation...')\n",
    "        refitted_model=retrained_model.fit(**paramdictFit,optimized=False) # Apply the already-optimised parameters to the new train+test dataset\n",
    "        nx1StepPred=refitted_model.model.predict(refitted_model.params,start=TS_test.index.min(),end=TS_test.index.max()) # Generate predictions\n",
    "        \n",
    "        ##### 6) Evaluate the N x 1-step model fit (MAPE, RMSE, etc.)\n",
    "        nx1Stepfit=error_calcs(TS_test,nx1StepPred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##### 7) Store all the results etc. in a dictionary, and append to a list of all iterations\n",
    "        model_dict={'Trained_on':ser,\\\n",
    "                    'hyperparameters':hyperparams,\\\n",
    "                   'Fitted Model':model_fit,\\\n",
    "                   'Test size (N)':len(TS_test),\\\n",
    "                    'Model summary':model_fit.summary(),\\\n",
    "                   'Output parameters':model_fit.params,\\\n",
    "                    'Retraining parameters (Model)':paramdictModel, # Same as the output parameters, but parsed to form the inputs needed at the MODEL stage for refitting\\\n",
    "                    'Retraining parameters (Fit)':paramdictFit, # Same as the output parameters, but parsed to form the inputs needed at the FIT stage for refitting\\\n",
    "                    'AIC':model_fit.aic,\\\n",
    "                    'N-step fit':nStepfit,\\\n",
    "                    'N x 1-step fit':nx1Stepfit,\\\n",
    "                    'Refitted Params (QA)':refitted_model.params} # Verify they are indeed the same!\n",
    "                   \n",
    "        hw_models.append(model_dict)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Select best model and use for actual forecast (rather than test forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_AIC=min([x['AIC'] for x in hw_models])\n",
    "best_Nstep=min([x['N-step fit']['MAPE'] for x in hw_models])\n",
    "best_1step=min([x['N x 1-step fit']['MAPE'] for x in hw_models])\n",
    "#best_model=[x for x in hw_models if x['N x 1-step fit']['MAPE']==best_1step][0]\n",
    "#best_model=[x for x in hw_models if x['N-step fit']['MAPE']==best_Nstep][0]\n",
    "best_model=[x for x in hw_models if x['AIC']==best_AIC][0]\n",
    "\n",
    "# Check parameters were applied correctly\n",
    "print(best_model['Refitted Params (QA)'])\n",
    "print(best_model['Output parameters'])\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FinalTraining=training_sets[best_model['Trained_on']].append(TS_test)\n",
    "if best_model['hyperparameters'][1]==None:\n",
    "    final_model=ExponentialSmoothing(FinalTraining, trend=best_model['hyperparameters'][0],freq=datafreq,initialization_method='known',**best_model['Retraining parameters (Model)'])\n",
    "else:\n",
    "    final_model=ExponentialSmoothing(FinalTraining, trend=best_model['hyperparameters'][0],seasonal=best_model['hyperparameters'][1]\\\n",
    "                               ,seasonal_periods=best_model['hyperparameters'][2],freq=datafreq,initialization_method='known',**best_model['Retraining parameters (Model)'])\n",
    "\n",
    "\n",
    "fitted_final_model=final_model.fit(**best_model['Retraining parameters (Fit)'],optimized=False) # Apply the already-optimised parameters to the new train+test dataset\n",
    "\n",
    "predictions=fitted_final_model.model.predict(fitted_final_model.params,start=FinalTraining.index.min(),end=TS.index.max()) # Generate predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comparedf=pd.DataFrame(TS[FinalTraining.index.min():])\n",
    "comparedf['predicted']=predictions\n",
    "comparedf.plot(ylim=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts=fitted_final_model.model.predict(fitted_final_model.params,start=FinalTraining.index.max(),end='2021-01-01') # Generate predictions\n",
    "forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc=pd.Series(forecasts)\n",
    "fc.plot(ylim=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc[1:-1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
