{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up:\n",
    "1) Modules\n",
    "2) Credentials & keys for Trello and Google Sheets\n",
    "3) Load Trello board\n",
    "4) Configure pandas output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up modules\n",
    "import pandas as pd\n",
    "import sys\n",
    "import requests\n",
    "from xlsxwriter.utility import xl_rowcol_to_cell\n",
    "sys.path.append(r'/home/jupyter/reusable_code')\n",
    "import google_api_functions as gaf\n",
    "import trello_generic as tg\n",
    "import sqlite3\n",
    "from google.cloud import bigquery # To run BQ statements\n",
    "import re\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import json\n",
    "# Set up SQL DB\n",
    "conn = sqlite3.connect('SQL_connection1.db') #Create a connection object\n",
    "\n",
    "# Set up credentials for Trello and Google \n",
    "\n",
    "# Google Sheets Credentials\n",
    "creds=gaf.Authenticate_Google(r'/home/jupyter/reusable_code/') # Return logged-in credentials\n",
    "\n",
    "# General setup and credentials: Trello\n",
    "from trello import TrelloClient\n",
    "trelloUserCreds=tg.readTrelloCredsFromFile(r'/home/jupyter/reusable_code/trellocreds.pickle')\n",
    "mykey,mysecret,mytoken=trelloUserCreds\n",
    "\n",
    "client = TrelloClient(api_key=mykey,api_secret=mysecret,token=mytoken)\n",
    "\n",
    "# Return Trello board, client and other credentials objects. \"myboard_creds\" is a tuple of items which can be unpacked\n",
    "# to cover off all of the various levels you might need access at\n",
    "dataBoard,dataBoard_id,dataBoard_creds=tg.Return_board_by_name(mykey,mysecret,mytoken,\"Data 2021\")\n",
    "researchBoard,researchBoard_id,researchBoard_creds=tg.Return_board_by_name(mykey,mysecret,mytoken,\"Research 2021\")\n",
    "#oldBoard,oldBoard_id,oldBoard_creds=tg.Return_board_by_name(mykey,mysecret,mytoken,\"Insights & Data\")\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign card numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardlist=dataBoard.get_cards() # Return all cards on board\n",
    "cardnums=[int(re.search('\\#(\\d{1,4})',i.name)[1]) for i in cardlist if re.search('\\#\\d{1,4}',i.name)!=None] # Identify where there are already card numbers in the format #number\n",
    "max_cardnum=np.max(cardnums) # Get the maximum card number on the board\n",
    "cards_without_num=[i for i in cardlist if re.search('\\#\\d{1,4}',i.name)==None] # List all cards without a number \n",
    "\n",
    "# Loop cards without a number and add one to their name\n",
    "for n,i in enumerate(cards_without_num):\n",
    "    i.set_name('#'+str(n+1+max_cardnum)+' '+i.name)\n",
    "    print('#'+str(n+1+max_cardnum)+' '+i.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Trello board into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCard_df,dataCard_list=tg.cards_to_dataframe(dataBoard_creds,checklist_options=None\\\n",
    "                           ,labels_as_binary_flags=True, label_colours=True,comment_names=False,get_attachments=True #)\n",
    "                                               ,card_number_cutoff=10000, \\\n",
    "                                                lists_to_exclude=['Template(s)','Ideation','No longer required','Completed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCard_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn \"New Insight Brief(s)\" into proper cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthToNum(shortMonth):\n",
    "    return {\n",
    "            'Jan' : '01',\n",
    "            'Feb' : '02',\n",
    "            'Mar' : '03',\n",
    "            'Apr' : '04',\n",
    "            'May' : '05',\n",
    "            'Jun' : '06',\n",
    "            'Jul' : '07',\n",
    "            'Aug' : '08',\n",
    "            'Sep' : '09', \n",
    "            'Oct' : '10',\n",
    "            'Nov' : '11',\n",
    "            'Dec' : '12'\n",
    "    }[shortMonth]\n",
    "\n",
    "\n",
    "def Process_New_Insight_Briefs():\n",
    "    MonthLookup={}\n",
    "    \n",
    "    New_briefs=[i for i in dataCard_list if i['Name']=='New Insight Brief' and i['List'] in ['New Projects (need prioritisation)','Backlog', 'Prioritised','In Progress']]\n",
    "    labellist=dataBoard.get_labels()\n",
    "    for i in New_briefs:\n",
    "            CardInfo=re.split('Sent via Google Form Notifications',i['Description'])[0] # Take the bit before the generic email signature\n",
    "            print(CardInfo)\n",
    "            \n",
    "            #############################\n",
    "            # Reset card name\n",
    "            #############################\n",
    "            i['Card Object'].set_name(re.search('\\*Project Name\\*: \\*(.*)\\*',CardInfo)[1])\n",
    "\n",
    "            #############################\n",
    "            # Set Due Date            \n",
    "            #############################\n",
    "            DeadlineInfo=re.search('\\*Needed by: \\*(.*)',CardInfo)[1]\n",
    "            #print(DeadlineInfo)\n",
    "            try:\n",
    "                DueDate=datetime.strptime(DeadlineInfo[:12], '%b %d, %Y')\n",
    "                #print(DueDate)\n",
    "                i['Card Object'].set_due(DueDate)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try: \n",
    "                DueText=str(DueDate)[:10]\n",
    "            #print(DueText)\n",
    "                tg.Update_custom_field(dataBoard_creds,i['Trello ID'],'Hard Deadline',DueText)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            #############################\n",
    "            # Set labels for team        \n",
    "            #############################\n",
    "            try:\n",
    "                Team=re.search('\\*Submitted by\\*: .* in the (.+) team',CardInfo)[1]\n",
    "                try:\n",
    "                    LabelObject=[i for i in labellist if i.name==Team][0]\n",
    "                    i['Card Object'].add_label(LabelObject)\n",
    "                except:\n",
    "                    print('Could not add label for team: \"{}\"'.format(Team))\n",
    "            except:\n",
    "                pass\n",
    "          \n",
    "                \n",
    "            #############################\n",
    "            # Set labels for priorities/ projects            \n",
    "            #############################\n",
    "            projects=re.findall('\\*Supports projects\\*: (.*)',CardInfo)\n",
    "            if len(projects)>0:\n",
    "                projectList=re.split('\\n',projects[0])\n",
    "                for project in projectList:\n",
    "                    try:\n",
    "                        LabelObject=[i for i in labellist if i.name==project][0]\n",
    "                        i['Card Object'].add_label(LabelObject)\n",
    "                    except:\n",
    "                        print('Could not add label for project: \"{}\"'.format(project))\n",
    "    \n",
    "            #############################\n",
    "            # Set custom field (type)\n",
    "            #############################\n",
    "            WorkType=re.search('\\*(.*) brief\\*',CardInfo)[1]\n",
    "            if WorkType=='No idea- you tell me':            # If unknown leave blank\n",
    "                pass\n",
    "            else:\n",
    "                try:\n",
    "                    tg.Update_custom_field(dataBoard_creds,i['Trello ID'],'Type',WorkType)\n",
    "                except:\n",
    "                    print('Could not update Type field with value: {}'.format(WorkType))\n",
    "            \n",
    "            #############################\n",
    "            # Set custom field (Blocker) \n",
    "            try:\n",
    "                Blockerinfo= re.search('\\*Blocker: \\*(.*)? which should be resolved by',CardInfo)[1]\n",
    "                tg.Update_custom_field(dataBoard_creds,i['Trello ID'],'Blockers/ Dependencies 1',Blockerinfo)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Set custom field (Blocker date) \n",
    "            try:\n",
    "                Blockerdatetext= re.search('\\*Blocker: \\*.* which should be resolved by (.+)',CardInfo)[1]\n",
    "                BlockerDate= '-'.join([Blockerdatetext[8:12],monthToNum(Blockerdatetext[0:3]),Blockerdatetext[4:6]])   \n",
    "                tg.Update_custom_field(dataBoard_creds,i['Trello ID'],'Blocker 1 Due Date',BlockerDate)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Redo description            \n",
    "            NewDesc=re.split('Project Detail',CardInfo)[1]+'\\n Submitted By: '\\\n",
    "            +re.search('\\*Submitted by\\*: (.*)@...',CardInfo)[1].replace('.',' ')\\\n",
    "            +'\\nRequired by: '+DeadlineInfo\n",
    "            i['Card Object'].set_description(NewDesc)\n",
    "            \n",
    "            # If research move to research board\n",
    "            if WorkType=='Research':\n",
    "                tg.MoveCard(i['Card Object'],'5fe35ef42dd5616a3e37bc12',mykey,mytoken,boardid=researchBoard_id)\n",
    "    \n",
    "    return New_briefs\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "briefs=Process_New_Insight_Briefs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reimport\n",
    "dataCard_df,dataCard_list=tg.cards_to_dataframe(dataBoard_creds,checklist_options=None\\\n",
    "                           ,labels_as_binary_flags=True, label_colours=False,comment_names=False,get_attachments=True #)\n",
    "                                               ,card_number_cutoff=10000,lists_to_exclude=['Template(s)','Ideation','No longer required','Completed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds=gaf.Authenticate_Google(r'/home/jupyter/reusable_code/')\n",
    "bq = bigquery.Client(project='itv-bde-analytics-dev',credentials=creds)\n",
    "dataset=bq.dataset('britbox_sandbox')\n",
    "table_ref = dataset.table(\"SW_Data_Workstack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for amending then loading into BQ\n",
    "df_for_bq=dataCard_df.copy()\n",
    "\n",
    "# Most of the columns are \"object\" type, which holds mixed types. Explicitly make dates as such else it'll break load as it expects a \"bytes\" type then finds a datetime\n",
    "df_for_bq['Due Date'] = pd.to_datetime(df_for_bq['Due Date'].astype(str))\n",
    "df_for_bq['Card Created Date'] = pd.to_datetime(df_for_bq['Card Created Date'].astype(str))\n",
    "df_for_bq['Hard Deadline'] = pd.to_datetime(df_for_bq['Hard Deadline'].astype(str))\n",
    "df_for_bq['Blocker 1 Due Date'] = pd.to_datetime(df_for_bq['Blocker 1 Due Date'].astype(str))\n",
    "\n",
    "# Struggles to identify and load array of STRUCTs with different datatypes, so just don't for now\n",
    "\n",
    "df_for_bq=df_for_bq.drop(columns=['listMovementHistory', 'listMovementSummary','coordinates'])\n",
    "\n",
    "\n",
    "# Remove characters that you can't have in a BQ variable name\n",
    "newcol_names={x:x.replace(\" \", \"_\").replace(\"/\",\"\").replace(\"?\",\"\").replace(\"-\",\"\").replace(\"&\",\"\").replace(\":\",\"\").replace(\"(\",\"\").replace(\")\",\"\") for x in df_for_bq.columns}\n",
    "df_for_bq=df_for_bq.rename(columns=newcol_names)\n",
    "\n",
    "#Remove blank column names which might arise from blank labels on the board\n",
    "df_col=[i for i in df_for_bq.columns if len(i)>0] \n",
    "df_for_bq=df_for_bq[df_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_bq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bq.delete_table(table_ref)\n",
    "except:\n",
    "    pass\n",
    "job = bq.load_table_from_dataframe(df_for_bq, table_ref)\n",
    "\n",
    "job.result()  # Waits for table load to complete.\n",
    "print(\"Loaded dataframe to {}\".format(table_ref.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_bq.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy up DataFrame to include only the records and columns of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "create or replace table `itv-bde-analytics-dev.britbox_sandbox.SW_Data_Workstack1` as\n",
    "with x  as (select \n",
    "Name\n",
    ",Description\n",
    ",List\n",
    ",Card_Number\n",
    ",Due_Date\n",
    ",Trello_ID\n",
    ",Trello_URL\n",
    ",Card_Created_Date\n",
    ",Comments\n",
    ",Trello_attachments\n",
    ",Other_attachments\n",
    ",Blocker_1_Due_Date\n",
    ",Supported_by\n",
    ",Ad_hoc\n",
    ",Assigned_to\n",
    ",Blockers_Dependencies_1\n",
    ",Type\n",
    ",Subtype\n",
    ",Blockers_Dependencies_2\n",
    "--,Project_Brief_Location\n",
    ",Paused_or_Blocked\n",
    ",Mark_for_Deletion\n",
    ",Hard_Deadline\n",
    ",EPIC\n",
    "--,isEPIC\n",
    "\n",
    ",currentListTimeSpent\n",
    ",currentListTimesEntered\n",
    ",currentListFirstEntered\n",
    ",currentListLastEntered\n",
    ",listpos\n",
    ",cardpos\n",
    ",boardpos\n",
    "\n",
    ",split(Labels,'|') as labels1\n",
    "from `itv-bde-analytics-dev.britbox_sandbox.SW_Data_Workstack`\n",
    "where list not in ('Template(s)','No longer required')\n",
    ")\n",
    "\n",
    "select x.* except (labels1)\n",
    ", array_agg(case when trim(split(labels2,':')[safe_offset(1)])='green' then \n",
    "trim(split(labels2,':')[safe_offset(0)]) end ignore nulls) as Teams\n",
    ", array_agg(case when trim(split(labels2,':')[safe_offset(1)])='yellow' then \n",
    "trim(split(labels2,':')[safe_offset(0)]) end ignore nulls) as Priorities\n",
    ", array_agg(case when trim(split(labels2,':')[safe_offset(1)])='blue' then \n",
    "trim(split(labels2,':')[safe_offset(0)]) end ignore nulls) as TeamObjectives\n",
    "from x\n",
    "cross join unnest (labels1) as labels2\n",
    "group by 1,2,3,4,5,6,7,8,9,10\n",
    ",11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30\n",
    ";\"\"\"\n",
    "df = bq.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-prioritisation session admin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Move all cards from New to Backog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from_list=[i for i in dataBoard.list_lists() if i.name=='New Projects (need prioritisation)'][0]\n",
    "to_list=[i for i in dataBoard.list_lists() if i.name=='Backlog'][0]\n",
    "from_list.move_all_cards(to_list)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Move all cards from Recently Completed to Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from_list=[i for i in dataBoard.list_lists() if i.name=='Recently Completed'][0]\n",
    "to_list=[i for i in dataBoard.list_lists() if i.name=='Completed'][0]\n",
    "from_list.move_all_cards(to_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One off Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Set Hard Deadlines for historically processed cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for i in dataCard_list:\n",
    "    DeadlineInfo=None\n",
    "    DeadlineInfo=re.search('Required by: (.*)',i['Description'])\n",
    "\n",
    "    if DeadlineInfo!=None:\n",
    "        print(DeadlineInfo[1])\n",
    "        try:\n",
    "            DueDate=datetime.strptime(DeadlineInfo[1][:12], '%b %d, %Y')\n",
    "            print(DueDate)\n",
    "            DueText=str(DueDate)[:10]\n",
    "            print(DueText)\n",
    "            tg.Update_custom_field(dataBoard_creds,i['Trello ID'],'Hard Deadline',DueText)\n",
    "            print('Updated to {}'.format(DueText))\n",
    "        except:\n",
    "            pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataCard_list[:23]:\n",
    "    tg.Update_custom_field(dataBoard_creds,i['Trello ID'],'Hard Deadline','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One  off- assign members using assigned to field, so timelines can be grouped by member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Members=dataBoard.get_members()\n",
    "MemberDict={i.full_name:i for i in Members}\n",
    "MemberDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "assignees=list(dataCard_df['Assigned to'][dataCard_df['Assigned to'].notna()].unique())\n",
    "assignee_dict={i:None for i in assignees}\n",
    "\n",
    "for i in assignee_dict:\n",
    "    for j in MemberDict:\n",
    "        if i[:3].lower() ==j[:3].lower():\n",
    "            print(i,j)\n",
    "            assignee_dict[i]=j\n",
    "assignee_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "query = {'key': mykey,'token': mytoken}\n",
    "\n",
    "for i in dataCard_list:\n",
    "\n",
    "    if 'Assigned to' in i.keys():\n",
    "        print(i['Name'])\n",
    "        print(i['Assigned to'])\n",
    "\n",
    "        Member_needed=assignee_dict[i['Assigned to']]\n",
    "        print(Member_needed)\n",
    "        \n",
    "        url = \"https://api.trello.com/1/cards/{}/members\".format(i['Trello ID'])\n",
    "        response = requests.request(\"GET\",url,params=query)\n",
    "        if response.ok:\n",
    "            responses = json.loads(response.text)\n",
    "            if Member_needed in [i['fullName'] for i in responses]:\n",
    "                print('Ok')\n",
    "            else:\n",
    "                print('Missing')\n",
    "                i['Card Object'].add_member(MemberDict[Member_needed])\n",
    "                \n",
    "                \n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate start date as entered \"in progress\" list and end date as entered  \"complete\" accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataCard_list:\n",
    "    if i['List']=='In Progress':\n",
    "        print(i['Name'])\n",
    "        df=pd.DataFrame(i['listMovementSummary'])\n",
    "        print(df[['enteredList','FirstEntered','LastExited']][df['enteredList']=='In Progress'])\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCard_df[['Name','Blockers/ Dependencies 1','Blockers/ Dependencies 2']][dataCard_df['Blockers/ Dependencies 1'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map EPICs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import all cards including \"completed\"\n",
    "(NB the checklist import isn't working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCard_df,dataCard_list=tg.cards_to_dataframe(dataBoard_creds,checklist_options=None\\\n",
    "                           ,labels_as_binary_flags=True, label_colours=True,comment_names=False,get_attachments=True #)\n",
    "                                               ,card_number_cutoff=10000,lists_to_exclude=['Template(s)','Ideation','No longer required'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify EPICS (as cards with the isEPIC label applied... rather than using the \"EPIC\" field or being in the \"EPIC\" list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPICS=[]\n",
    "for i in dataCard_list:\n",
    "    if 'isEPIC' in i.keys():\n",
    "        if i['isEPIC']==True:\n",
    "            EPICS.append(i)\n",
    "#EPICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create EPIC labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labellist=dataBoard.get_labels()\n",
    "\n",
    "for i in EPICS:\n",
    "    EPIC_Name=re.sub('\\#(\\d{1,4}) ','',i['Name'])\n",
    "    if 'EPIC: {}'.format(EPIC_Name) not in [i.name for i in labellist]:\n",
    "        dataBoard.add_label('EPIC: {}'.format(EPIC_Name), color='lime')\n",
    "        print('Created new label: {}'.format(EPIC_Name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove labels that shouldn't be there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPIC_labels=[i for i in labellist if i.name[:4]=='EPIC']\n",
    "accepted_labels=['EPIC: {}'.format(re.sub('\\#(\\d{1,4}) ','',i['Name'])) for i in EPICS]\n",
    "\n",
    "for x in EPIC_labels:\n",
    "    if x.name not in accepted_labels:\n",
    "        print(x.name)\n",
    "        dataBoard.delete_label(x.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a mapping by looping through the checklists on each EPIC card of items assigned to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Epic_mapping={}\n",
    "for card in EPICS: #Loop epics\n",
    "    checklists_to_export=[i for i in card['Card Object'].checklists] # Get the checklists on the cards\n",
    "\n",
    "    for m,i in enumerate(checklists_to_export): # Loop the checklists\n",
    "        url = \"https://api.trello.com/1/checklists/{}/checkItems\".format(i.id)\n",
    "        querystring = {\"filter\":'all',\"fields\":'all',\"key\":mykey,\"token\":mytoken}\n",
    "        if i.name=='Sub Projects': # Return the items on the checklist if it's called \"Sub Projects\"\n",
    "            response = requests.request(\"GET\", url, params=querystring)\n",
    "            checklist_items=json.loads(response.text)\n",
    "            if checklist_items!=None:\n",
    "                for j in checklist_items:\n",
    "                    matched=re.search('https://trello.com/c/.{8}',j['name']) # Extract the common part of the URL\n",
    "                    try:\n",
    "                        Epic_mapping[matched[0]]={'URL':card['Trello URL'],'Label':'EPIC: {}'.format(re.sub('\\#(\\d{1,4} )','',card['Name'])) } #Store in a dictionary\n",
    "                    except:\n",
    "                        print('No match on {}'.format(j))\n",
    "Epic_mapping                        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for key in Epic_mapping:\n",
    "    for card in dataCard_list:\n",
    "        if key==card['Trello URL']:\n",
    "            print(key,Epic_mapping[key]['URL'])\n",
    "            tg.Update_custom_field(myboard_creds=dataBoard_creds, cardId=card['Trello ID'], customFieldname='EPIC', value=Epic_mapping[key]['URL']) # Update the custom field\n",
    "            \n",
    "            #Labels=[print(i.name,Epic_mapping[key]['Label']) for i in labellist]# if i.name==Epic_mapping[key]['Label']]\n",
    "            LabelObject=[i for i in labellist if i.name==Epic_mapping[key]['Label']][0]\n",
    "            if card[LabelObject.name]==False:\n",
    "                try:\n",
    "                    card['Card Object'].add_label(LabelObject)\n",
    "                except:\n",
    "                    print('Couldn''t do it')\n",
    "            else:\n",
    "                print('Already on')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project dependency graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload all cards (inc. Completes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCard_df,dataCard_list=tg.cards_to_dataframe(dataBoard_creds,checklist_options=None\\\n",
    "                           ,labels_as_binary_flags=True, label_colours=True,comment_names=False,get_attachments=True #)\n",
    "                                               ,card_number_cutoff=10000,lists_to_exclude=['Template(s)','Ideation','No longer required'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Colour palette "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "values,colourDf=gaf.read_google_sheets_as_rows('18t_E2ZBbFxxm32ApsajUMP1KGo--m2aqEO6xy4v4XvY','Sheet1',creds)\n",
    "colourDictHex=[{i['Colour']:i['HEX']} for i in colourDf[['Colour','HEX','Colour Palette']].to_dict('records') if i['Colour Palette']=='Overall']\n",
    "colourDictHexInternal=[{i['Colour']:i['HEX']} for i in colourDf[['Colour','HEX','Colour Palette']].to_dict('records') if i['Colour Palette']=='Internal' and i['Colour'][-9:]!='Highlight']\n",
    "#colourDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset the graph database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_EPIC_from_labels(label_string):\n",
    "    label_string=str(label_string)\n",
    "    list_of_labels=label_string.split('|')\n",
    "    list_of_labelDicts=[]\n",
    "    for i in list_of_labels:\n",
    "        split=i.split(':')\n",
    "        if len(split)>1:\n",
    "            list_of_labelDicts.append({split[0]:split[1]})\n",
    "    \n",
    "    label=[]\n",
    "    for dictobj in list_of_labelDicts:\n",
    "        for key in dictobj.keys():\n",
    "            if key.strip()=='EPIC':\n",
    "                label.append(dictobj[key].strip())\n",
    "                \n",
    "    if len(label)>0:\n",
    "        return label[0]\n",
    "    else:\n",
    "        return 'Standalone'\n",
    "    \n",
    "\n",
    "# Create sub df for use in graph build    \n",
    "graphdf=dataCard_df[['Name','Description','Trello URL','Card Number','Labels','Hard Deadline','Due Date','Type','Assigned to','EPIC','Depends on','Blockers/ Dependencies 1','Blockers/ Dependencies 2','Blocker 1 Due Date','Blocker 2 Due Date']].copy()   \n",
    "\n",
    "# Remove the number from the project name for display purposes\n",
    "graphdf['Name']=graphdf['Name'].apply(lambda x: re.sub('\\#(\\d{1,4} )','',x))\n",
    "\n",
    "# Apply the above function to extract the EPIC from the labels (or class as 'standalone' if not)\n",
    "graphdf['EPIC_Class']=graphdf['Labels'].apply(Get_EPIC_from_labels) \n",
    "\n",
    "# Turn the \"Depends on\" field into a list\n",
    "graphdf['Dependent']=graphdf['Depends on'].apply(lambda x:  str(x).split(',') if pd.notnull(x) else None) # Extract Dependent by Number\n",
    "\n",
    "####################################################################################################################################\n",
    "# Dataframe for Graph Edges\n",
    "####################################################################################################################################\n",
    "# Create an edge df by looking at the dependencies field and the blockers field\n",
    "\n",
    "edge_df=graphdf[graphdf['Dependent'].notna()][['Name','Dependent']].explode('Dependent')# Explode out the dependencies\n",
    "edge_df['Dependent']=edge_df['Dependent'].astype(int) # Convert from string to integer\n",
    "edge_df=edge_df.merge(graphdf,left_on='Dependent',right_on='Card Number')[['Name_x','Name_y']].rename(columns={'Name_x':'To','Name_y':'From'}) # Match edges using dependents field\n",
    "\n",
    "# Create a df holding on the stuff in the dependencies fields, which holds off-board dependencies\n",
    "external_edges=pd.concat([\n",
    "graphdf[graphdf['Blockers/ Dependencies 2'].notna()][['Name','Blockers/ Dependencies 2','EPIC_Class']].rename(columns={'Name':'To','Blockers/ Dependencies 2':'From'}),\n",
    "graphdf[graphdf['Blockers/ Dependencies 1'].notna()][['Name','Blockers/ Dependencies 1','EPIC_Class']].rename(columns={'Name':'To','Blockers/ Dependencies 1':'From'})])\n",
    "\n",
    "# Union it in to the dataframe\n",
    "edge_df=pd.concat([edge_df,external_edges[['To','From']]])\n",
    "\n",
    "# Package up the from/to into a Tuple for plugging into NetworkX\n",
    "edge_df['Tuple'] = list(zip(edge_df['From'],edge_df['To']))\n",
    "\n",
    "\n",
    "####################################################################################################################################\n",
    "# Dataframe for Graph Nodes\n",
    "####################################################################################################################################\n",
    "# Create a df to hold the nodes not in cards on my board that are referenced in the edges (BDE projects, etc.)\n",
    "extranodes=external_edges.groupby(['From','EPIC_Class']).count().drop(columns=['To']).reset_index()\n",
    "extranodes_df = pd.DataFrame(index=range(0,len(extranodes)),columns = list(graphdf.columns))\n",
    "extranodes_df['Name']=extranodes['From']\n",
    "extranodes_df['EPIC_Class']=extranodes['EPIC_Class'] \n",
    "extranodes_df['Type']='External' # hard code the type field\n",
    "\n",
    "\n",
    "# Concatenate  \n",
    "nodedf=graphdf.append(extranodes_df,ignore_index=True)\n",
    "nodedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extranodes=external_edges[['From','EPIC_Class']].unique()\n",
    "extranodes=external_edges.groupby(['From','EPIC_Class']).count().drop(columns=['To']).reset_index()\n",
    "extranodes_df = pd.DataFrame(index=range(0,len(extranodes)),columns = list(graphdf.columns))\n",
    "\n",
    "\n",
    "extranodes_df['Name']=extranodes['From']\n",
    "extranodes_df['EPIC_Class']=extranodes['EPIC_Class']\n",
    "extranodes_df['Type']='External'\n",
    "extranodes_df\n",
    "nodedf=graphdf.append(extranodes_df,ignore_index=True)\n",
    "nodedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodedf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodedf['HoverText']='Name: '+nodedf['Name']+'<br>'+'URL: '+nodedf['Trello URL']+'<br>'+'Type: '+nodedf['Type']\n",
    "\n",
    "# Create a colour map for use in epics\n",
    "classes=nodedf['EPIC_Class'].unique()\n",
    "loops_round=int(np.ceil(len(classes)/len(colourDictHexInternal)))\n",
    "\n",
    "\n",
    "colourMapEPIC={}\n",
    "for n,i in enumerate(classes):\n",
    "    for loop in range(0,loops_round):\n",
    "        for m,j in enumerate(colourDictHexInternal):\n",
    "            if n==(loop*len(colourDictHexInternal)+m):\n",
    "                print(i)\n",
    "                print(j)\n",
    "                print(colourDictHexInternal[j])\n",
    "                colourMapEPIC[i]=colourMapEPIC[colourDictHexInternal[j]]\n",
    "                \n",
    "colourMapEPIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "colours=[i.values() for i in colourDictHexInternal]\n",
    "colours[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "import networkx as nx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.DiGraph()\n",
    "G.add_nodes_from(nodedf['Name'])\n",
    "G.add_edges_from(edge_df['Tuple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=nx.spring_layout(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_x = []\n",
    "edge_y = []\n",
    "#for edge in G.edges():\n",
    "#    x0, y0 = G.nodes[edge[0]]['pos']\n",
    "#    x1, y1 = G.nodes[edge[1]]['pos']\n",
    "#    edge_x.append(x0)\n",
    "#    edge_x.append(x1)\n",
    "#    edge_x.append(None)\n",
    "#    edge_y.append(y0)\n",
    "#    edge_y.append(y1)\n",
    "#    edge_y.append(None)\n",
    "    \n",
    "    \n",
    "for frm,to in G.edges():\n",
    "    x0, y0 = pos[frm]\n",
    "    x1, y1 = pos[to]\n",
    "    edge_x.append(x0)\n",
    "    edge_x.append(x1)\n",
    "    edge_x.append(None) # I think the line property in normal circumstances is obviously one continuous line of x_coords and y_coords. \n",
    "    #To mimic edges, there is a gap to break the lines up so they only ever go \"from\"-> \"to\"\n",
    "    edge_y.append(y0)\n",
    "    edge_y.append(y1)\n",
    "    edge_y.append(None)    \n",
    "\n",
    "edge_trace = go.Scatter(\n",
    "    x=edge_x, y=edge_y,\n",
    "    line=dict(width=0.5, color='#888'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines')\n",
    "\n",
    "# Split the dict into lists for use in plotly\n",
    "node_x = []\n",
    "node_y = []\n",
    "for node in G.nodes():\n",
    "    x, y = pos[node]\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "\n",
    "node_trace = go.Scatter(x=node_x, y=node_y,\n",
    "                        mode='markers',hoverinfo='text',hovertext=nodedf['HoverText'],marker=dict(\n",
    "        showscale=True,\n",
    "\n",
    "        color=[],\n",
    "        size=10,\n",
    "        colorbar=dict(\n",
    "            thickness=15,\n",
    "            title='Node Connections',\n",
    "            xanchor='left',\n",
    "            titleside='right'\n",
    "        ),\\\n",
    "        line_width=2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#node_trace.marker.color=nodedf['EPIC_Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodedf['EPIC_Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "             layout=go.Layout(\n",
    "                title='<br>Network graph made with Python',\n",
    "                titlefont_size=16,\n",
    "                showlegend=False,\n",
    "                hovermode='closest',\n",
    "                margin=dict(b=20,l=5,r=5,t=40),\n",
    "                annotations=[ dict(\n",
    "                    text=\"Python code: <a href='https://plotly.com/ipython-notebooks/network-graphs/'> https://plotly.com/ipython-notebooks/network-graphs/</a>\",\n",
    "                    showarrow=False,\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "                    x=0.005, y=-0.002 ) ],\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "arrows=[]   \n",
    "\n",
    "for frm,to in G.edges():\n",
    "\n",
    "    arrow = go.layout.Annotation(dict(\n",
    "\n",
    "                x=pos[to][0]\n",
    "\n",
    "        ,y= pos[to][1],\n",
    "\n",
    "                xref=\"x\", yref=\"y\",\n",
    "\n",
    "                text=\"\",\n",
    "\n",
    "                showarrow=True,\n",
    "\n",
    "                axref = \"x\", ayref='y',ax= pos[frm][0],ay= pos[frm][1],\n",
    "\n",
    "                arrowhead = 4,\n",
    "\n",
    "                arrowwidth=3,\n",
    "\n",
    "                arrowcolor='rgb(255,51,0)',)\n",
    "\n",
    "            )\n",
    "\n",
    "    arrows.append(arrow)\n",
    "\n",
    "node_x = []\n",
    "node_y = []\n",
    "for node in G.nodes():\n",
    "    x, y = pos[node]\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "\n",
    "node_trace = go.Scatter(x=node_x, y=node_y,\n",
    "                        mode='markers',hoverinfo='text',hovertext=nodedf['HoverText'],\n",
    "                        text=nodedf['Name'],\n",
    "                        marker=dict(\n",
    "        showscale=True,\n",
    "        \n",
    "        color=[],\n",
    "        size=10,\n",
    "        colorbar=dict(\n",
    "            thickness=15,\n",
    "            title='Node Connections',\n",
    "            xanchor='left',\n",
    "            titleside='right'\n",
    "        ),\\\n",
    "        line_width=2))\n",
    "\n",
    " \n",
    "\n",
    "fig = go.Figure(data=[node_trace],\n",
    "\n",
    "             layout=go.Layout(\n",
    "\n",
    "                title='<br>Network graph made with Python',\n",
    "\n",
    "                titlefont_size=16,\n",
    "\n",
    "                showlegend=False,\n",
    "\n",
    "                hovermode='closest',\n",
    "\n",
    "                margin=dict(b=20,l=5,r=5,t=40),\n",
    "\n",
    "                annotations=[ dict(\n",
    "\n",
    "                    text=\"Python code: <a href='https://plotly.com/ipython-notebooks/network-graphs/'> https://plotly.com/ipython-notebooks/network-graphs/</a>\",\n",
    "\n",
    "                    showarrow=False,\n",
    "\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "\n",
    "                    x=0.005, y=-0.002 ) ],\n",
    "\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "\n",
    "                )\n",
    "\n",
    "arrows.append(arrows[0]) #For some bizarre reason it leaves off the first one, so I re-add it to the list\n",
    "\n",
    "fig.update_layout(annotations= arrows,)\n",
    "\n",
    " \n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
