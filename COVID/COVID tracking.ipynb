{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up modules for Google functionality\n",
    "from google.cloud import bigquery # To run BQ statements\n",
    "from google_auth_oauthlib import flow # To authorise as user\n",
    "from googleapiclient.discovery import build # To pull in from sheets, slides etc. API\n",
    "from google.auth.transport.requests import Request\n",
    "from google.cloud.bigquery import magics\n",
    "\n",
    "# Display\n",
    "import pprint\n",
    "\n",
    "# Operating system stuff\n",
    "import pickle\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "# Data handling\n",
    "import json\n",
    "import requests\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "import re\n",
    "\n",
    "# Stats, models, datasheets\n",
    "import pandas as pd\n",
    "import pyreadstat\n",
    "import math\n",
    "\n",
    "# Visualisation\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_venn # For venn diagrams\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "# Network graphs\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "# Misc\n",
    "from xlsxwriter.utility import xl_rowcol_to_cell # Used to create cell references\n",
    "import itertools\n",
    "\n",
    "sys.path.append(r'/home/jupyter/reusable_code')\n",
    "\n",
    "import google_api_functions as gaf\n",
    "creds=gaf.Authenticate_Google(r'/home/jupyter/reusable_code/') # Return logged-in credentials\n",
    "\n",
    "\n",
    "#sys.path.append(r'/Users/stepwate/Python Codes/Reusable Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tableau resources from John Hopkins available here:\n",
    "https://www.tableau.com/covid-19-coronavirus-data-resources\n",
    "\n",
    "Specific Google Sheet holding info is here:\n",
    "https://docs.google.com/spreadsheets/d/14quQPFErG-hlpsrNgYcX85vW7JMMK5X2vNZrafRcH8c/edit#gid=1815215449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bq = bigquery.Client(project='itv-bde-analytics-dev',credentials=creds) #Apply credentials to BQ client \"bq\"\n",
    "\n",
    "magics.context.credentials = creds  #apply these credentials to the BQ magic syntax too\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a Google Sheet\n",
    "values,confirmed_df=gaf.read_google_sheets_as_rows('14quQPFErG-hlpsrNgYcX85vW7JMMK5X2vNZrafRcH8c','COVID-19 Confirmed',creds,header_row=0)\n",
    "values,deaths_df=gaf.read_google_sheets_as_rows('14quQPFErG-hlpsrNgYcX85vW7JMMK5X2vNZrafRcH8c','COVID-19 Deaths',creds,header_row=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_df[confirmed_df['Country_Region']=='United Kingdom'].Province_State.unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client(project=\"itv-bde-analytics-dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table_ref = client.dataset('britbox_sandbox').table(\"sw_covid_confirmed\")\n",
    "job = client.load_table_from_dataframe(confirmed_df, table_ref, location=\"EU\")\n",
    "\n",
    "job.result()  # Waits for table load to complete.\n",
    "print(\"Loaded dataframe to {}\".format(table_ref.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table_ref = client.dataset('britbox_sandbox').table(\"sw_covid_deaths\")\n",
    "job = client.load_table_from_dataframe(deaths_df, table_ref, location=\"EU\")\n",
    "\n",
    "job.result()  # Waits for table load to complete.\n",
    "print(\"Loaded dataframe to {}\".format(table_ref.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery df\n",
    "SELECT Province_State, SUM(cast(Difference as int64)) as count\n",
    "FROM `itv-bde-analytics-dev.britbox_sandbox.sw_covid_confirmed`\n",
    "where \n",
    "Country_Region='United Kingdom'\n",
    "GROUP BY 1\n",
    "ORDER BY count DESC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery df\n",
    "create or replace table `itv-bde-analytics-dev.britbox_sandbox.sw_covid_uk`\n",
    "as select\n",
    "coalesce(cases.date_value,deaths.date_value) as date_value,\n",
    "ifnull(new_daily_cases,0) as new_daily_cases,\n",
    "ifnull(cumulative_cases,0) as cumulative_cases,\n",
    "ifnull(new_daily_deaths,0) as new_daily_deaths,\n",
    "ifnull(cumulative_deaths,0) as cumulative_deaths\n",
    "from\n",
    "(SELECT cast(Cases as int64) as cumulative_cases,\n",
    "cast(Difference as int64) as new_daily_cases,\n",
    "parse_date(\"%m/%d/%Y\",date) as date_value\n",
    "FROM `itv-bde-analytics-dev.britbox_sandbox.sw_covid_confirmed`\n",
    "where Country_Region='United Kingdom' and Province_State='N/A'\n",
    ") cases\n",
    "full join\n",
    "(SELECT cast(Cases as int64) as cumulative_deaths,\n",
    "cast(Difference as int64) as new_daily_deaths,\n",
    "parse_date(\"%m/%d/%Y\",date) as date_value\n",
    "FROM `itv-bde-analytics-dev.britbox_sandbox.sw_covid_deaths`\n",
    "where Country_Region='United Kingdom' and Province_State='N/A'\n",
    ") deaths\n",
    "on cases.date_value=deaths.date_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT date_value, new_daily_deaths,new_daily_cases\n",
    "    FROM `itv-bde-analytics-dev.britbox_sandbox.sw_covid_uk`\n",
    "\"\"\"\n",
    "query_job = client.query(\n",
    "        query\n",
    "    )  # API request - starts the query\n",
    "\n",
    "df = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('date_value').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between daily deaths and the number of daily new cases N days ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_lag_corr=[]\n",
    "for i in range(0,50):\n",
    "    query = \"\"\"\n",
    "    SELECT new_daily_deaths, lag(new_daily_cases,{}) over (order by date_value) as lagged_cases\n",
    "    FROM `itv-bde-analytics-dev.britbox_sandbox.sw_covid_uk`\n",
    "    where new_daily_deaths>0\n",
    "\"\"\".format(i)\n",
    "    query_job = client.query(\n",
    "        query\n",
    "    )  # API request - starts the query\n",
    "\n",
    "    df = query_job.to_dataframe()\n",
    "    death_lag_corr.append({'lag':i,'corr':df.corr()['new_daily_deaths'].loc['lagged_cases']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df=pd.DataFrame(death_lag_corr)\n",
    "\n",
    "correlation_df.plot('corr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df[correlation_df['corr']==correlation_df['corr'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between daily cumulative deaths and the number of cumulative cases N days ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_lag_corr2=[]\n",
    "for i in range(0,50):\n",
    "    query = \"\"\"\n",
    "    SELECT cumulative_deaths, lag(cumulative_cases,{}) over (order by date_value) as lagged_cases\n",
    "    FROM `itv-bde-analytics-dev.britbox_sandbox.sw_covid_uk`\n",
    "    where cumulative_deaths>0\n",
    "\"\"\".format(i)\n",
    "    query_job = client.query(\n",
    "        query\n",
    "    )  # API request - starts the query\n",
    "\n",
    "    df = query_job.to_dataframe()\n",
    "    death_lag_corr2.append({'lag':i,'corr':df.corr()['cumulative_deaths'].loc['lagged_cases']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df_cum=pd.DataFrame(death_lag_corr2)\n",
    "correlation_df_cum.plot('corr')\n",
    "correlation_df_cum[correlation_df_cum['corr']==correlation_df_cum['corr'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    , lag(new_daily_cases,6) over (order by date_value) as lag6_cases\n",
    "    , lag(cumulative_cases,6) over (order by date_value) as lag6_cases_cum\n",
    "    FROM `itv-bde-analytics-dev.britbox_sandbox.sw_covid_uk`\n",
    "\"\"\".format(i)\n",
    "query_job = client.query(\n",
    "        query\n",
    "    )  # API request - starts the query\n",
    "\n",
    "full_covid_df = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_covid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = full_covid_df[\"lag6_cases_cum\"][6:]\n",
    "y = full_covid_df[\"cumulative_deaths\"][6:]\n",
    "\n",
    "# Note the difference in argument order\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X) # make the predictions by the model\n",
    "\n",
    "# Print out the statistics\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_covid_df['modelled_deaths']=0.1741*full_covid_df['lag6_cases_cum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_covid_df[['cumulative_deaths','modelled_deaths']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(full_covid_df['cumulative_deaths']/full_covid_df['modelled_deaths']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pd.DataFrame(np.log(full_covid_df['cumulative_deaths'][7:]),np.log(full_covid_df['modelled_deaths'][7:])).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_covid_df[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.2081*(88621-55242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.2081*(88621-55242)+11329"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_covid_df[\"lag6_cases\"][6:]\n",
    "y = full_covid_df[\"new_daily_deaths\"][6:]\n",
    "\n",
    "# Note the difference in argument order\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X) # make the predictions by the model\n",
    "\n",
    "# Print out the statistics\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_covid_df['modelled_deaths_daily']=0.2000*full_covid_df['lag6_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_covid_df[['new_daily_deaths','modelled_deaths_daily']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "full_covid_df['future_date']= full_covid_df[\"date_value\"]+ timedelta(days=6)\n",
    "full_covid_df['future_deaths_daily']= 0.2000*full_covid_df['new_daily_cases']\n",
    "full_covid_df['future_deaths_cumulative']= 0.2081*full_covid_df['cumulative_cases']\n",
    "full_covid_df[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_covid_df.set_index('date_value')['cumulative_cases'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_covid_df.set_index('date_value')['new_daily_cases'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.stats\n",
    "\n",
    "y=full_covid_df['cumulative_cases'].to_numpy()\n",
    "sc=StandardScaler() \n",
    "yy = y.reshape (-1,1)\n",
    "sc.fit(yy)\n",
    "y_std =sc.transform(yy)\n",
    "y_std = y_std.flatten()\n",
    "y_std\n",
    "del yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = getattr(scipy.stats, 'expon')\n",
    "param = dist.fit(y_std)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set list of distributions to test\n",
    "# See https://docs.scipy.org/doc/scipy/reference/stats.html for more\n",
    "\n",
    "# Set up list of candidate distributions to use\n",
    "# See https://docs.scipy.org/doc/scipy/reference/stats.html for more\n",
    "\n",
    "dist_names = ['beta',\n",
    "              'expon',\n",
    "              'gamma',\n",
    "              'lognorm',\n",
    "              'norm',\n",
    "              'pearson3',\n",
    "              'triang',\n",
    "              'uniform',\n",
    "              'weibull_min', \n",
    "              'weibull_max']\n",
    "\n",
    "# Set up empty lists to store results\n",
    "p_values = []\n",
    "\n",
    "\n",
    "# Loop through candidate distributions\n",
    "\n",
    "for distribution in dist_names:\n",
    "    # Set up distribution and get fitted distribution parameters\n",
    "    dist = getattr(scipy.stats, distribution)\n",
    "    param = dist.fit(y_std)\n",
    "    \n",
    "    # Obtain the KS test P statistic, round it to 5 decimal places\n",
    "    p = scipy.stats.kstest(y_std, distribution, args=param)[1]\n",
    "    p = np.around(p, 5)\n",
    "    p_values.append(p)    \n",
    "    \n",
    "    \n",
    "# Collate results and sort by goodness of fit (best at top)\n",
    "\n",
    "results = pd.DataFrame()\n",
    "results['Distribution'] = dist_names\n",
    "results['p_value'] = p_values\n",
    "\n",
    "    \n",
    "# Report results\n",
    "\n",
    "print ('\\nDistributions sorted by goodness of fit:')\n",
    "print ('----------------------------------------')\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(y))\n",
    "size = len(y)\n",
    "# Set list of distributions to test\n",
    "# See https://docs.scipy.org/doc/scipy/reference/stats.html for more\n",
    "\n",
    "# Turn off code warnings (this is not recommended for routine use)\n",
    "\n",
    "\n",
    "# Set up list of candidate distributions to use\n",
    "# See https://docs.scipy.org/doc/scipy/reference/stats.html for more\n",
    "\n",
    "dist_names = ['beta',\n",
    "              'expon',\n",
    "              'gamma',\n",
    "              'lognorm',\n",
    "              'norm',\n",
    "              'pearson3',\n",
    "              'triang',\n",
    "              'uniform',\n",
    "              'weibull_min', \n",
    "              'weibull_max']\n",
    "\n",
    "# Set up empty lists to stroe results\n",
    "chi_square = []\n",
    "p_values = []\n",
    "\n",
    "# Set up 50 bins for chi-square test\n",
    "# Observed data will be approximately evenly distrubuted aross all bins\n",
    "percentile_bins = np.linspace(0,100,51)\n",
    "percentile_cutoffs = np.percentile(y_std, percentile_bins)\n",
    "observed_frequency, bins = (np.histogram(y_std, bins=percentile_cutoffs))\n",
    "cum_observed_frequency = np.cumsum(observed_frequency)\n",
    "\n",
    "# Loop through candidate distributions\n",
    "\n",
    "for distribution in dist_names:\n",
    "    # Set up distribution and get fitted distribution parameters\n",
    "    dist = getattr(scipy.stats, distribution)\n",
    "    param = dist.fit(y_std)\n",
    "    \n",
    "    # Obtain the KS test P statistic, round it to 5 decimal places\n",
    "    p = scipy.stats.kstest(y_std, distribution, args=param)[1]\n",
    "    p = np.around(p, 5)\n",
    "    p_values.append(p)    \n",
    "    \n",
    "    # Get expected counts in percentile bins\n",
    "    # This is based on a 'cumulative distrubution function' (cdf)\n",
    "    cdf_fitted = dist.cdf(percentile_cutoffs, *param[:-2], loc=param[-2], \n",
    "                          scale=param[-1])\n",
    "    expected_frequency = []\n",
    "    for bin in range(len(percentile_bins)-1):\n",
    "        expected_cdf_area = cdf_fitted[bin+1] - cdf_fitted[bin]\n",
    "        expected_frequency.append(expected_cdf_area)\n",
    "    \n",
    "    # calculate chi-squared\n",
    "    expected_frequency = np.array(expected_frequency) * size\n",
    "    cum_expected_frequency = np.cumsum(expected_frequency)\n",
    "    ss = sum (((cum_expected_frequency - cum_observed_frequency) ** 2) / cum_observed_frequency)\n",
    "    chi_square.append(ss)\n",
    "        \n",
    "# Collate results and sort by goodness of fit (best at top)\n",
    "\n",
    "results = pd.DataFrame()\n",
    "results['Distribution'] = dist_names\n",
    "results['chi_square'] = chi_square\n",
    "results['p_value'] = p_values\n",
    "results.sort_values(['chi_square'], inplace=True)\n",
    "    \n",
    "# Report results\n",
    "\n",
    "print ('\\nDistributions sorted by goodness of fit:')\n",
    "print ('----------------------------------------')\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
