{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To run this script, you will need your user token (generate one if you don't have it).\n",
    "https://github.com/settings/tokens\n",
    "\n",
    "And save it as a file called _github_token.txt_ in a folder called _reusable_code_ on the Jupyter home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbformat import read, write\n",
    "import github\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import pathlib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick up Github token for authentication purposes \n",
    "mytoken=open('/home/jupyter/reusable_code/github_personal_token.txt',\"r\").read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create GitHub connection/ instance\n",
    "g = github.Github(mytoken)\n",
    "\n",
    "# Get your specific user (update with your username)\n",
    "myuser=g.get_user()\n",
    "print(myuser.login)\n",
    "\n",
    "# Subset to just the ITV repo\n",
    "#ITV_org=g.get_organization('ITV').get_repos()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#myuser.create_repo(name='backup_ITV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_repo=myuser.get_repo(name='backup_ITV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove outputs from notebooks to make the file sizes smaller. Later on, the API struggles to download \n",
    "# contents of files greater than 1MB so you don't want visuals etc.\n",
    "\n",
    "def strip_output(nb):\n",
    "    for cell in nb.cells:\n",
    "        if hasattr(cell, \"outputs\"):\n",
    "            cell.outputs = []\n",
    "        if hasattr(cell, \"prompt_number\"):\n",
    "            del cell[\"prompt_number\"]\n",
    "\n",
    "#nb = read(open(filepath), 4)\n",
    "#strip_output(nb)\n",
    "#write(nb, open(\"my_notebook_cleaned.ipynb\", \"w\"), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=r'/home/jupyter/' # Specify directory to loop through\n",
    "myfiles=[] # Initialise empty list\n",
    "\n",
    "file_exceptions=['client_secrets.json','TalonOneAPIKey.txt','token.pickle','trellocreds.pickle','github_token.txt','github_personal_token.txt'] # Define list of files to exempt\n",
    "extensions=['.ipynb','.py','.txt','.sql'] # Define file extensions to include (in lower case)\n",
    "\n",
    "extensions=[i.lower() for i in extensions]\n",
    "for root, dirs, files in os.walk(directory): # Iterate all folders and subfolders\n",
    "    for name in files:\n",
    "        if name[0]!='.' and name not in file_exceptions and pathlib.Path(name).suffix.lower() in extensions:  # Ignore files beginning with '.'-- these are system checkpoints\n",
    "            \n",
    "            if len([x for x in root.split('/') if len(x)>0 and x[0]=='.'])>0:  # Ditto ignore folders with '.'\n",
    "                #print('Not a good path: ',os.path.join(root, name))\n",
    "                pass\n",
    "            else:\n",
    "                filepath=os.path.join(root, name)\n",
    "                #print(filepath)\n",
    "                myfiles.append(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset=['/home/jupyter/reusable_code/trello_generic.py','/home/jupyter/BritBox Admin/Export Insight Workstack.ipynb']\n",
    "subset=[i for i in myfiles if i.split('/')[3][:5]!='bbdig' and i.split('/')[3]!='dataserv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_updates=[]\n",
    "#for filepath in myfiles: # Loop through files in local directory\n",
    "for filepath in subset: # Loop through files in local directory\n",
    "    \n",
    "    now = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\") # Store timestamp\n",
    "    destPath=filepath.replace(directory,'') # Determine the directory name to write to\n",
    "    \n",
    "    # Before backing up, we need to sanitise the notebook file(s) and remove outputs, which make the files massive, because you cannot then later update them\n",
    "    if pathlib.Path(filepath).suffix.lower()=='.ipynb':\n",
    "        nb = read(open(filepath), 4) # Open file\n",
    "        strip_output(nb) # Run function defined above to remove outputs\n",
    "        write(nb, open(\"my_notebook_cleaned.ipynb\", \"w\"), 4) # Store in a temporary location\n",
    "        filecontents=open(\"my_notebook_cleaned.ipynb\", 'rb').read() # Now re-read that templocation in as bytes (that's what the 'rb' does))\n",
    "    else:\n",
    "        filecontents=open(filepath, 'rb').read()\n",
    "        \n",
    "\n",
    "    # Check if the file exists already\n",
    "    existing_content=None # Reset var to None\n",
    "    \n",
    "    # If file exists, update it\n",
    "    try:\n",
    "        existing_content=backup_repo.get_contents(path=destPath)\n",
    "        backup_repo.update_file(path=destPath,message='Lazy backup at {}'.format(now),content=filecontents,sha=existing_content.sha)\n",
    "        print('Updated {}'.format(filepath))\n",
    "    except Exception as ex:\n",
    "        # print(ex)\n",
    "        try:\n",
    "            # If file doesn't exist, create it\n",
    "            backup_repo.create_file(path=destPath,message='Lazy backup at {}'.format(now),content=filecontents)\n",
    "            print('Loaded {}'.format(filepath))\n",
    "        except Exception as ex2:\n",
    "            print(ex2)\n",
    "            print ('Could not update or create file: {}'.format(filepath))\n",
    "            failed_updates.append(filepath)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for filepath in failed_updates[:15]: # Loop through files in local directory\n",
    "    now = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\") # Store timestamp\n",
    "    destPath=filepath.replace(directory,'') # Determine the directory name to write to\n",
    "    \n",
    "    # Before backing up, we need to sanitise the notebook file(s) and remove outputs, which make the files massive, because you cannot then later update them\n",
    "    if pathlib.Path(filepath).suffix.lower()=='.ipynb':\n",
    "        nb = read(open(filepath), 4) # Open file\n",
    "        strip_output(nb) # Run function defined above to remove outputs\n",
    "        write(nb, open(\"my_notebook_cleaned.ipynb\", \"w\"), 4) # Store in a temporary location\n",
    "        filecontents=open(\"my_notebook_cleaned.ipynb\", 'rb').read() # Now re-read that templocation in as bytes (that's what the 'rb' does))\n",
    "    else:\n",
    "        filecontents=open(filepath, 'rb').read()\n",
    "        \n",
    "\n",
    "    # Check if the file exists already\n",
    "    existing_content=None # Reset var to None\n",
    "    \n",
    "    # If file exists, update it\n",
    "    try:\n",
    "        existing_content=backup_repo.get_contents(path=destPath)\n",
    "        backup_repo.update_file(path=destPath,message='Lazy backup at {}'.format(now),content=filecontents,sha=existing_content.sha)\n",
    "        print('Updated {}'.format(filepath))\n",
    "    except Exception as ex:\n",
    "        # print(ex)\n",
    "        try:\n",
    "            # If file doesn't exist, create it\n",
    "            backup_repo.create_file(path=destPath,message='Lazy backup at {}'.format(now),content=filecontents)\n",
    "            print('Loaded {}'.format(filepath))\n",
    "        except Exception as ex2:\n",
    "            print(ex2)\n",
    "            print ('Could not update or create file: {}'.format(filepath))\n",
    "            failed_updates.append(filepath)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
