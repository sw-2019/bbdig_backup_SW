{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U scikit-learn\n",
    "import sklearn\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import AgglomerativeClustering,KMeans, DBSCAN, OPTICS, Birch\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import silhouette_score #Silhouette score basically represents the intra-cluster distance. You want it to be as large as poss (to maximise distance between clusters and so uniqueness)\n",
    "import plotly.express as px\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(r'/home/jupyter/reusable_code')\n",
    "import google_api_functions as gaf\n",
    "from google.cloud import bigquery # To run BQ statements\n",
    "creds=gaf.Authenticate_Google(r'/home/jupyter/reusable_code/') # Return logged-in credentials\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq = bigquery.Client(project='itv-bde-analytics-dev',credentials=creds)\n",
    "query='''select * from\n",
    "`itv-bde-analytics-dev.britbox_sandbox.SW_Viewing_Programme_Score_4`'''\n",
    "df = bq.query(query).to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='depth_rate', y='pc_cross_Sell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a \"graph labels\" column that fills in the name only if certain criteria are met\n",
    "df.loc[(df['pc_cross_Sell'] <= 0.83) | (df['depth_rate'] >= 0.65), 'Graph_labels'] = df['programme']  \n",
    "\n",
    "\n",
    "# Plot\n",
    "fig = px.scatter(df, x='depth_rate', y='pc_cross_Sell', log_x=False, size_max=100)\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.update_layout(title_text='Programme Groupings', title_x=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot\n",
    "fig = px.scatter(df, x='watched', y='watched_depth', log_x=False, size_max=100,hover_data=['watched','watched_depth','programme'],trendline=\"ols\")\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.update_layout(title_text='Programme Groupings', title_x=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "x=np.array(df.watched).reshape((-1, 1))\n",
    "y=df.watched_depth\n",
    "model.fit(x, y)\n",
    "r_sq = model.score(x, y)\n",
    "r_sq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Watched_depth_pred'] = model.predict(x)\n",
    "df['Watched_depth_pred']= df['Watched_depth_pred'].apply(lambda x: x if x>0 else 1) # Overwrite negative values\n",
    "df['Watched_depth_performance']=(df['watched_depth']/df['Watched_depth_pred'])-1\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig = px.scatter(df[df['Viewer_rank']<100], x='watched', y='watched_depth', log_x=True, size_max=100,hover_data=['watched','watched_depth','programme'],color='Watched_depth_performance')\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.update_layout(title_text='Programme Groupings', title_x=0.5)\n",
    "fig.show()\n",
    "\n",
    "df[df['Viewer_rank']<100][['programme','watched','Watched_depth_pred','watched_depth','Watched_depth_performance','depth_rate']].sort_values(by='Watched_depth_performance',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define array of values to cluster on\n",
    "X=df[['depth_rate','pc_cross_Sell']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/clustering-algorithms-with-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/clustering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbow = []\n",
    "kmax = 10\n",
    "for k in range(2, kmax+1):\n",
    "    kmeans = KMeans(n_clusters = k).fit(X)\n",
    "    elbow.append(kmeans.inertia_)\n",
    "    \n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(np.arange(2,11), elbow)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia (Intra cluster sum of squares)')\n",
    "plt.title('Inertia vs n_clusters to determine optimal cluster size', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/opening-the-black-box-of-clustering-kmeans-e970062ff415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sil = []\n",
    "elbow = []\n",
    "kmax = 10\n",
    "for k in range(2, kmax+1):\n",
    "    kmeans = KMeans(n_clusters = k).fit(X)\n",
    "    elbow.append(kmeans.inertia_)\n",
    "    labels = kmeans.labels_\n",
    "    sil.append(silhouette_score(X, labels, metric = 'euclidean'))\n",
    "    \n",
    "plt.figure(figsize=(8,6))\n",
    "#plt.plot(np.arange(2,11), elbow)\n",
    "plt.plot(np.arange(2,11), sil)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia (Intra cluster sum of squares)')\n",
    "plt.title('Inertia vs n_clusters to determine optimal cluster size', fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a function to map a colour to cluster number\n",
    "def get_colour(x):\n",
    "    if x ==0:\n",
    "        return 'red'\n",
    "    elif x ==1:\n",
    "        return 'blue'\n",
    "    elif x ==2:\n",
    "        return 'purple'\n",
    "    elif x ==3:\n",
    "        return 'orange'\n",
    "    elif x ==4:\n",
    "        return 'yellow'\n",
    "    elif x ==5:\n",
    "        return 'green'\n",
    "    elif x ==6:\n",
    "        return 'brown'\n",
    "    elif x ==7:\n",
    "        return 'pink'\n",
    "    elif x ==8:\n",
    "        return 'cyan'\n",
    "    else:\n",
    "        return 'olive'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agglomerative clustering\n",
    "\n",
    "\n",
    "\n",
    "# define the model/ methodology used for clustering\n",
    "\n",
    "model = GaussianMixture(n_components=7) # Decent\n",
    "model = KMeans(n_clusters=5) # Decent (ish) results\n",
    "model = AgglomerativeClustering(n_clusters=6,linkage='complete') # Best model IMO, Single linkage is the worst (picks up on the outliers)\n",
    "model= DBSCAN(eps=0.01,min_samples=1) # Poor Results\n",
    "model= OPTICS() # Poor Results\n",
    "model= Birch(threshold=0.01,n_clusters=6) # Fair Results\n",
    "\n",
    "model = AgglomerativeClustering(n_clusters=6,linkage='complete') # Best model IMO, Single linkage is the worst (picks up on the outliers)\n",
    "\n",
    "# fit model and predict clusters\n",
    "yhat = model.fit_predict(X)\n",
    "# retrieve unique clusters\n",
    "clusters = unique(yhat)\n",
    "\n",
    "# Map clusters back onto the dataframe\n",
    "df['clusterNum']=yhat\n",
    "\n",
    "# Add a column to the dataframe to say what colour to use\n",
    "df['color']= df['clusterNum'].apply(get_colour)\n",
    "\n",
    "\n",
    "# Visualise segments on scatter plot\n",
    "fig = px.scatter(df, x='depth_rate', y='pc_cross_Sell', log_x=False, size_max=10, size=np.log(df['total_episodes_in_programme']),color='clusterNum',hover_data=['pc_cross_Sell','depth_rate','programme','watched','clusterNum'])\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.update_layout(title_text='Programme Groupings', title_x=0.5)\n",
    "fig.show()\n",
    "\n",
    "fig2 = px.scatter(df, x='depth_rate', y='pc_cross_Sell', log_x=False, size_max=10, size=np.log(df['watched']),color='clusterNum',hover_data=['pc_cross_Sell','depth_rate','programme','watched','clusterNum'])\n",
    "fig2.show()\n",
    "\n",
    "# Visualise df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataset=bq.dataset('britbox_sandbox')\n",
    "table_ref = dataset.table(\"SW_Viewing_Programme_Score_5\")\n",
    "\n",
    "newcol_names={x:x.replace(\" \", \"_\").replace(\"/\",\"\").replace(\"?\",\"\").replace(\"-\",\"\").replace(\".\",\"\") for x in df.columns}\n",
    "df_for_bq=df.rename(columns=newcol_names)\n",
    "\n",
    "try:\n",
    "    bq.delete_table(table_ref)\n",
    "except:\n",
    "    pass\n",
    "job = bq.load_table_from_dataframe(df_for_bq, table_ref)\n",
    "\n",
    "job.result()  # Waits for table load to complete.\n",
    "print(\"Loaded dataframe to {}\".format(table_ref.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Viewer_rank']<=19].sort_values(by='watched_depth',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Viewer_rank']<=30].sort_values(by='depth_rate', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfforPresentation= df.copy()\n",
    "dfforPresentation['Classification']=df['programme'].apply(lambda x:\\\n",
    "                                                         'Bad Content' if x in ['First Tuesday','Strictly Come Dancing','All Creatures Great and Small','Famalam','Royal Shakespeare Company',\"Hugh's Fat Fight\"]\\\n",
    "                                                          else ('Good Content' if x in ['DCI Banks','Brief Encounters','Life Begins','Silk','The Syndicate','Scott & Bailey'] else \\\n",
    "                                                                ('Top 7' if x in ['Love Island','New Spitting Image','The Only Way is Essex','Broadchurch','Doctor Who Classic','Vera','Only Fools and Horses'] else\\\n",
    "                                                                 'Other')))\n",
    "\n",
    "# Visualise segments on scatter plot\n",
    "fig = px.scatter(dfforPresentation, x='depth_rate', y='pc_cross_Sell', log_x=False, size_max=10, size=np.log(dfforPresentation['total_episodes_in_programme']),\\\n",
    "                 color='Classification',hover_data=['pc_cross_Sell','depth_rate','programme','watched','clusterNum'])\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.update_layout(title_text='Programme Groupings', title_x=0.5)\n",
    "fig.show()\n",
    "\n",
    "# Visualise df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
